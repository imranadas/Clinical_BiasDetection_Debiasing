{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da05133-8f88-41d3-b1be-81f17d8df88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd())\n",
    "import argparse\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from utils import MIMICDataset, extract_embeddings, get_emb_size\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from run_classifier_dataset_utils import InputExample, convert_examples_to_features\n",
    "import Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e2827-e818-4581-9f27-b2335b8c5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('''Given a BERT model and a dataset with a 'seqs' column, outputs a pickled dictionary\n",
    "                                 mapping note_id to 2D numpy array, where each array is num_seq x emb_dim''')\n",
    "parser.add_argument('--df_path', help = 'must have the following columns: seqs, num_seqs, and note_id either as a column or index')\n",
    "parser.add_argument('--model_path', type = str)\n",
    "parser.add_argument('--output_path', type = str)\n",
    "parser.add_argument('--emb_method', default = 'last', const = 'last', nargs = '?', choices = ['last', 'sum4', 'cat4'], help = 'how to extract embeddings from BERT output')\n",
    "args = parser.parse_args()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1ad734-5410-4d0d-be4d-2802efd4823d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(args.df_path)\n",
    "if 'note_id' in df.columns:\n",
    "    df = df.set_index('note_id')\n",
    "tokenizer = BertTokenizer.from_pretrained(args.model_path)\n",
    "model = BertModel.from_pretrained(args.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca29a49-656a-457b-b613-90cad226b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_input_example(note_id, text, seqIdx):\n",
    "    return InputExample(guid = '%s-%s'%(note_id,seqIdx), text_a = text, text_b = None, label = 0, group = 0, other_fields = [])\n",
    "\n",
    "examples = [convert_input_example(idx, i, c) for idx, row in df.iterrows() for c,i in enumerate(row.seqs)]\n",
    "features = convert_examples_to_features(examples,\n",
    "                                        Constants.MAX_SEQ_LEN, tokenizer, output_mode = 'classification')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "model.to(device)\n",
    "\n",
    "if n_gpu > 1:\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "generator = data.DataLoader(MIMICDataset(features, 'train', 'classification'),  shuffle = True,  batch_size = n_gpu*32)\n",
    "\n",
    "EMB_SIZE = get_emb_size(args.emb_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9048aae-f0c5-4268-a3b2-d627736f4a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embs(generator):\n",
    "    model.eval()\n",
    "    embs = {str(idx):np.zeros(shape = (row['num_seqs'], EMB_SIZE), dtype = np.float32) for idx, row in df.iterrows()}\n",
    "    with torch.no_grad():\n",
    "        for input_ids, input_mask, segment_ids, _, _, guid, _ in tqdm(generator):\n",
    "            input_ids = input_ids.to(device)\n",
    "            segment_ids = segment_ids.to(device)\n",
    "            input_mask = input_mask.to(device)\n",
    "            hidden_states, _ = model(input_ids, token_type_ids = segment_ids, attention_mask = input_mask)\n",
    "            bert_out = extract_embeddings(hidden_states, args.emb_method)\n",
    "\n",
    "            for c,i in enumerate(guid):\n",
    "                note_id, seq_id = i.split('-')\n",
    "                emb = bert_out[c,:].detach().cpu().numpy()\n",
    "                embs[note_id][int(seq_id), :] = emb\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346fab49-a8d3-4e7c-a285-ce6c9e7260c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "odel_name = os.path.basename(os.path.normpath(args.model_path))\n",
    "pickle.dump(get_embs(generator), open(args.output_path, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
